{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***User Manual***\n",
    "- Go to [API - Google AI Studio](https://aistudio.google.com/apikey) to get the API key.\n",
    "- Install the necessary libraries \n",
    "    - `pip install -q -U google-genai`\n",
    "    - `pip install python-dotenv tqdm pillow`\n",
    "- Create a `.env` file in the same dir as the notebook with the content `GEMINI_API_KEY = \"YOUR_API_KEY\"`\n",
    "- Hàm chính cần quan tâm là `load_generation` vs cái `prompt` bên trong `generate` là ổn nhé.\n",
    "    - Chạy cái hàm `load_generation` là được.\n",
    "    - Có thể đọc phần docstring ở hàm `load_generation` để tham khảo.\n",
    "\n",
    "### ***API Limitation***\n",
    "Hiện tại chúng ta đang dùng của Gemini free nên cơ bản mình sẽ bị những thứ sau:\n",
    "- 15 RPM (Request per minute)\n",
    "- 1 mil TPM (Total per minute)\n",
    "- 1500 RPD (Request per day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from time import sleep\n",
    "\n",
    "from google import genai\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Load environment variables from a .env file. This is often used to store sensitive information like API keys.\n",
    "load_dotenv()\n",
    "# Define a tuple containing common image file extensions. This might be used later to identify image files.\n",
    "IMAGE_EXT = (\".jpg\", \".jpeg\", \".png\", \".gif\", \".webp\", \".tiff\")\n",
    "\n",
    "# Configure the Google Generative AI library with the API key obtained from the environment variables.\n",
    "CLIENT = genai.Client(api_key = os.getenv(\"GEMINI_API_KEY\"))\n",
    "# Marking using the \"gemini-2.0-flash\" model.\n",
    "# This model can be used for various generative tasks, including text and image generation.\n",
    "MODEL = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(img_path, num = 5):\n",
    "    prompt = f\"\"\"\n",
    "    Bạn là một chuyên gia phân tích các số liệu thống kê từ infographic tin tức.  \n",
    "    Dựa vào hình ảnh được cung cấp, hãy đề xuất các cặp câu hỏi - câu trả lời liên quan đến việc đếm các đối tượng thoả mãn một tiêu chí nào đó  \n",
    "    Hãy thể hiện sự sáng tạo của bạn trong việc đặt câu hỏi và trả lời.\n",
    "\n",
    "    Các quy tắc cần tuân theo:\n",
    "    - Bao gồm {int(num * 0.6)} câu hỏi yêu cầu đếm các đối tượng dựa trên một tính chất liên quan đến các yếu tố dạng text (số liệu, thông tin dạng văn bản, ...). Nếu câu hỏi liên quan đến số liệu, câu hỏi được yêu cầu phải thêm các thông tin như lớn hơn hoặc nhỏ hơn 1 giá trị nào đó hoặc là trong 1 khoảng giá trị nào đó. Nếu câu hỏi liên quan đến việc đếm số tên gọi, cầu hỏi được yêu cầu phải thêm thông tin như tên gọi đó bắt đầu bằng 1 từ hoặc 1 cụm từ cụ thể nào đó.\n",
    "    - Bao gồm {int(num * 0.4)} câu hỏi yêu cầu đếm các đối tượng dựa trên một tính chất liên quan đến các yếu tố dạng non-text (các yếu tố phi văn bản như hình dạng biểu đồ, vị trí trên bản đồ, các vật thể (con người, cây cối, ...), ...). \n",
    "    - Trước khi đặt những câu hỏi, hãy quan sát infographic trước và tìm ra những nội dụng chính mà tấm infographic đó muốn truyền tải, từ đó đặt những câu hỏi liên quan đến nội dung chính đó. \n",
    "    - Không được phép đặt những câu hỏi thiếu sự chi tiết, quá tổng quát và khó định danh chính xác thông tin trên infographic để trả lời (ví dụ: Không được đặt là \"Có bao nhiêu hình người xuất hiện trong infographic?\" mà nên đặt là \"Có bao nhiêu hình người xuất hiện hình bên trái ở phần \"...\" của Infographic?\") \n",
    "    - Câu hỏi và câu trả lời phải ở dạng câu hoàn chỉnh, đồng thời, câu trả lời phải được viết rõ ràng, đề cập đầy đủ các ý được hỏi từ câu hỏi. \n",
    "    - Chỉ sử dụng thông tin có trong infographic, không bổ sung kiến thức nền tảng bên ngoài. \n",
    "    - Không tạo câu hỏi có dạng có/không hoặc dạng lựa chọn.\n",
    " \n",
    "    - Không đặt câu hỏi yêu cầu phân tích sâu hoặc suy luận ngoài dữ liệu infographic.\n",
    "    - Không được đặt những câu hỏi mà không đủ dữ kiện hay số liệu để đưa ra câu trả lời tương ứng.\n",
    "    - Xử lý các biểu đồ, đồ thị, bản đồ và các yếu tố phi văn bản một cách hợp lý.\n",
    "    - Câu hỏi và câu trả lời không được quá 30 từ.\n",
    "    - Thêm thông tin sau vào mỗi câu trả lời:\n",
    "      + Explanation: Ở phần này, bạn hãy đưa ra lý do cụ thể (không quá 100 từ) rằng tại sao bạn lại đưa ra câu trả lời như thế, vì là các câu hỏi liên quan đến việc đếm nên lúc này, bạn hãy chỉ rõ tên của các đối tượng được đếm trong lời giải thích của bạn. Yêu cầu: Lời giải thích phải được viết thành đoạn văn, không được gạch đầu dòng. \n",
    "    - Không đưa ra những câu hỏi có thể trả lời câu hỏi đó mà không cần nhìn vào infographic (ví dụ: \"Trong 4 quốc gia Việt Nam, Mông Cổ, Myanmar, Malaysia, quốc gia nào không có tên bắt đầu bằng chữ M\", ở câu này bạn không cần phải nhìn vào infographic vẫn có thể trả lời chính xác, điều này là không được phép!)\n",
    "    \n",
    "    Hãy trả lời theo cấu trúc sau:\n",
    "    ---\n",
    "    Q: (câu hỏi)  \n",
    "    A: (câu trả lời)  \n",
    "    Explanation: (Lời giải thích cho câu trả lời của bạn) \n",
    "    Type: (Text nếu câu hỏi yêu cầu đếm các yếu tố dạng text hoặc Non-text nếu câu hỏi yêu cầu đếm các yếu tố dạng non-text)\n",
    "    ---\n",
    "    \"\"\"\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "    response = CLIENT.models.generate_content(\n",
    "        model=MODEL,\n",
    "        contents=[prompt, img],\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "def clean(text: str):\n",
    "    \"\"\"\n",
    "    Cleans a text string by removing extra spaces and replacing double quotes with single quotes.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text string to clean.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned text string.\n",
    "    \"\"\"\n",
    "    patterns = {\n",
    "        r\"\\s+\": \" \",  # replace multiple spaces with a single space\n",
    "        r\"\\\"\": \"'\",  # replace double quotes with single quotes to avoid JSON parsing error\n",
    "    }\n",
    "    text = text.strip()\n",
    "    for pattern, repl in patterns.items():\n",
    "        text = re.sub(pattern, repl, text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def extract(response: str, start_ques = \"Q: \", start_ans = \"A: \", start_exp = \"Explanation: \", start_type = \"Type: \"):\n",
    "    \"\"\"\n",
    "    Extracts questions, answers, explanations, and types from the generated text response.\n",
    "\n",
    "    Args:\n",
    "        response (str): The generated text containing the question-answer pairs.\n",
    "        start_ques (str, optional): The starting string for questions. Defaults to \"Q: \".\n",
    "        start_ans (str, optional): The starting string for answers. Defaults to \"A: \".\n",
    "        start_exp (str, optional): The starting string for explanations. Defaults to \"Explanation: \".\n",
    "        start_type (str, optional): The starting string for types. Defaults to \"Type: \".\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary contains a question, answer, explanation, and type.\n",
    "    \"\"\"\n",
    "    questions = []\n",
    "    answers = []\n",
    "    explanations = []\n",
    "    types = []\n",
    "\n",
    "    for line in response.split(\"\\n\"):\n",
    "        if line.startswith(start_ques):\n",
    "            questions.append(clean(line[len(start_ques) : ]))\n",
    "        elif line.startswith(start_ans):\n",
    "            answers.append(clean(line[len(start_ans) : ]))\n",
    "        elif line.startswith(start_exp):\n",
    "            explanations.append(clean(line[len(start_exp) : ]))\n",
    "        elif line.startswith(start_type):\n",
    "            types.append(clean(line[len(start_type) : ]))\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"Question\": q,\n",
    "            \"Answer\": a,\n",
    "            \"Explanation\": e,\n",
    "            \"Type\": t\n",
    "        }\n",
    "        for q, a, e, t in zip(questions, answers, explanations, types)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_generation(folder: str, num: int = 5, prefix: str = \"qa_\", sleep_time: int = 1):\n",
    "    \"\"\"\n",
    "    Load images from a specified folder and perform a generation process\n",
    "    (presumably generating questions and answers related to the images).\n",
    "\n",
    "    Process:\n",
    "    - Reads existing generated data from a JSON file (creates a new one if it doesn't exist).\n",
    "    - Identifies images in the folder that haven't been processed yet.\n",
    "    - Generates questions and answers for each unprocessed image.\n",
    "\n",
    "    Parameters:\n",
    "    - folder (str): The path to the folder containing the image files.\n",
    "    - num (int): The number of question-answer pairs to generate for each image (total 2*num generated).\n",
    "    - prefix (str): The prefix to be used for the name of the JSON file where the generated data is saved.\n",
    "    - sleep_time (int): The number of seconds to wait between processing each image.\n",
    "\n",
    "    Returns:\n",
    "    - None. The generated data is saved to a JSON file.\n",
    "    \"\"\"\n",
    "    def save_json(data, qa_file):\n",
    "        \"\"\"\n",
    "        Saves the generated data to a JSON file.\n",
    "\n",
    "        Parameters:\n",
    "        - data (dict): The dictionary containing the generated data.\n",
    "        - qa_file (str): The path to the JSON file to save the data to.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        with open(qa_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"[+] Saved to {qa_file}\")\n",
    "\n",
    "    data = {}\n",
    "    qa_file = prefix + folder + \".json\"\n",
    "    # Check if the JSON file exists and is not empty\n",
    "    if os.path.isfile(qa_file) and os.path.getsize(qa_file) > 0:\n",
    "        # Load existing data from the JSON file\n",
    "        with open(qa_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "    else:\n",
    "        # Create a new empty JSON file if it doesn't exist\n",
    "        with open(qa_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            pass\n",
    "\n",
    "    # Get a list of image files in the specified folder that have not been processed yet\n",
    "    images = [f for f in os.listdir(folder) if f.endswith(IMAGE_EXT) and f not in data]\n",
    "    # If there are no new images to process\n",
    "    if not images:\n",
    "        print(\"[+] All done!\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Iterate through the unprocessed images with a progress bar\n",
    "        with tqdm(total=len(images), unit=\" in4graphic\", dynamic_ncols=True) as pbar:\n",
    "            for img in images:\n",
    "                pbar.set_description(f\"Processing {img}\")\n",
    "                img_path = os.path.join(folder, img)\n",
    "                # Retry loop for handling potential errors, especially \"Too Many Requests\"\n",
    "                while True:\n",
    "                    try:\n",
    "                        # Call the 'generate' function (assumed to be defined elsewhere)\n",
    "                        # to generate data for the current image.\n",
    "                        # Then, call the 'extract' function (assumed to be defined elsewhere)\n",
    "                        # to process the generated data.\n",
    "                        data[img] = extract(generate(img_path, num=num))\n",
    "                        pbar.update(1)\n",
    "                        sleep(sleep_time)\n",
    "                        break  # Exit the retry loop on successful processing\n",
    "                    except Exception as e:\n",
    "                        # Handle \"Too Many Requests\" error by waiting and retrying\n",
    "                        if \"429\" in str(e):\n",
    "                            print(\"[-] Received 429 Too Many Requests. Retrying after 10 seconds...\")\n",
    "                            sleep(10)\n",
    "                        else:\n",
    "                            raise  # Re-raise other exceptions that are not rate-limiting errors\n",
    "        # Save the updated data to the JSON file after processing all images\n",
    "        save_json(data, qa_file)\n",
    "\n",
    "    # Handle potential exceptions during the process, including keyboard interrupts\n",
    "    except (Exception, KeyboardInterrupt) as e:\n",
    "        print(f\"[-] Error: {e if not isinstance(e, KeyboardInterrupt) else 'Interrupted'}\")\n",
    "        # Save the current state of the data to the JSON file in case of an error or interruption\n",
    "        save_json(data, qa_file)\n",
    "\n",
    "# Example usage of the function\n",
    "load_generation(\"Part3\", num = 5, sleep_time = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
