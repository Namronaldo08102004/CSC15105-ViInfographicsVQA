{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3422db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import google.generativeai as genai\n",
    "import ast\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageFile\n",
    "import imagehash\n",
    "from dotenv import load_dotenv\n",
    "from time import sleep\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4014b3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "reader = easyocr.Reader(['vi', 'en'])\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key = os.getenv(\"GEMINI_API_KEY\"))\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf9f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Hugging Face Hub utilities\n",
    "from huggingface_hub.hf_api import HfFolder  # For handling authentication tokens\n",
    "from huggingface_hub import Repository, HfApi  # Tools for managing repositories on Hugging Face Hub\n",
    "\n",
    "REPO_ACCESS_TOKEN = \"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\"\n",
    "# Save the Hugging Face authentication atoken\n",
    "HfFolder.save_token(REPO_ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa5375c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43927d12ec6c4ab3892dc35ef3cede8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43a4fef5a8c4f7f8105e924dee32bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e71f38fdef4cae9bd556645013b95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7a572c20894356ad23e3d4a8240173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed50a5fd30054b0caed6f7cb6ae668c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38187555a8654c74b454f2e171b88ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07228ef0b6654fe7895cfc69481d2c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af79f43ffe5d4696965ef8e1916b1cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964e7f54fb424992ae6c159b3a36a442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f2f31acdc04612af863c2b84106eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d7a4d2618c41628ee8ff4875c5942a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc7850fc2f24b47a395416808c64a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_hf_dataset = load_dataset(\"Namronaldo2004/ViInfographicsVQA\", split = \"val\", streaming = True)\n",
    "test_hf_dataset = load_dataset(\"Namronaldo2004/ViInfographicsVQA\", split = \"test\", streaming = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "546d87a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to read dataset from the index 13559 to the index 13885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning dataset: 13716it [1:34:46, 18.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Resizing large image at index 13716: original size (1500, 21406)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning dataset: 13885it [2:37:52,  1.47it/s] \n"
     ]
    }
   ],
   "source": [
    "def fix_list_string(raw_str: str) -> str:\n",
    "    # Bước 1: Dọn sạch chuỗi đầu vào\n",
    "    raw_str = raw_str.strip()\n",
    "\n",
    "    # Bước 2: Chèn dấu phẩy giữa các dấu \" liền nhau nếu có\n",
    "    raw_str = re.sub(r'\"\\s*\"', '\", \"', raw_str)\n",
    "\n",
    "    # Bước 3: Parse từng dòng\n",
    "    lines = raw_str.strip('[]').split('\\n')\n",
    "    cleaned_lines = []\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip().rstrip(',')\n",
    "\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Loại bỏ dấu \" bao ngoài nếu có\n",
    "        if line.startswith('\"') and line.endswith('\"'):\n",
    "            line = line[1:-1]\n",
    "\n",
    "        # Escape các dấu \" bên trong nội dung\n",
    "        line = line.replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"')\n",
    "\n",
    "        # Thêm lại dấu \" bao ngoài\n",
    "        line = f'\"{line}\"'\n",
    "\n",
    "        # Thêm dấu phẩy nếu chưa phải dòng cuối\n",
    "        if i < len(lines) - 1:\n",
    "            line += ','\n",
    "\n",
    "        cleaned_lines.append(line)\n",
    "\n",
    "    fixed_str = '[\\n' + '\\n'.join(cleaned_lines) + '\\n]'\n",
    "    return fixed_str\n",
    "\n",
    "implementor = \"Nam\"\n",
    "with open (f\"{implementor}_val_index.txt\", 'r', encoding = 'utf-8') as file:\n",
    "    lst = file.read().strip('\\n').split()\n",
    "    start_index = int(lst[0])\n",
    "    end_index = int(lst[1])\n",
    "    print(f\"Start to read dataset from the index {start_index} to the index {end_index}\")\n",
    "    \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "count = 0\n",
    "count_ocr = 0\n",
    "oldImage = None\n",
    "api_error = False\n",
    "\n",
    "for sample in tqdm(val_hf_dataset, desc = \"Scanning dataset\"):\n",
    "    try:\n",
    "        if (count < start_index):\n",
    "            count += 1\n",
    "            count_ocr += 1\n",
    "            continue\n",
    "                                                             \n",
    "        # OCR + Gemini \n",
    "        image = sample[\"image\"]  # Load image from dataset\n",
    "        image_np = np.array(image)\n",
    "        image = Image.fromarray(image_np) \n",
    "        \n",
    "        if count == start_index or imagehash.phash(image) != imagehash.phash(oldImage):\n",
    "            oldImage = image\n",
    "            count_ocr = count\n",
    "            ocr_chunks = reader.readtext(image_np)\n",
    "            ocr_chunks = list(chunk[1] for chunk in ocr_chunks)\n",
    "            \n",
    "            prompt = f\"\"\"Bạn nhận được một danh sách văn bản ngắn, trích xuất từ ảnh infographic (OCR).\n",
    "            \n",
    "            Yêu cầu:\n",
    "            - Gom nhóm các dòng có liên quan theo ngữ cảnh.\n",
    "            - Viết lại thành các câu hoàn chỉnh, ngắn gọn, rõ nghĩa dùng để thực hiện text embedding.\n",
    "            - Trả về **duy nhất một Python list hợp lệ** chứa các câu, ví dụ:\n",
    "            ```python\n",
    "            [\n",
    "                \"Câu hoàn chỉnh 1.\",\n",
    "                \"Câu hoàn chỉnh 2.\",\n",
    "                ...\n",
    "            ]\n",
    "            \n",
    "            Dữ liệu:\n",
    "            {ocr_chunks}\n",
    "            \n",
    "            \"\"\"\n",
    "            \n",
    "            MAX_WEBP_SIZE = 16383\n",
    "            try:\n",
    "                resample_mode = Image.Resampling.LANCZOS\n",
    "            except AttributeError:\n",
    "                resample_mode = Image.LANCZOS  # For Pillow < 10.0\n",
    "\n",
    "            if image.width > MAX_WEBP_SIZE or image.height > MAX_WEBP_SIZE:\n",
    "                print(f\"[!] Resizing large image at index {count}: original size {image.size}\")\n",
    "                \n",
    "                resize_ratio = min(MAX_WEBP_SIZE / image.width, MAX_WEBP_SIZE / image.height)\n",
    "                new_size = (int(image.width * resize_ratio), int(image.height * resize_ratio))\n",
    "                \n",
    "                image = image.resize(new_size, resample=resample_mode)\n",
    "                image_np = np.array(image)  # Update numpy version too\n",
    "\n",
    "            count_429 = 0\n",
    "            while (True):\n",
    "                try:\n",
    "                    response = model.generate_content([prompt, image])\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    if \"429\" in str(e):\n",
    "                        print(\"[-] Received 429 Too Many Requests. Retrying after 10 seconds...\")\n",
    "                        count_429 += 1\n",
    "                        \n",
    "                        if (count_429 < 6):\n",
    "                            sleep(10)\n",
    "                        else:\n",
    "                            api_error = True\n",
    "                            raise\n",
    "                    elif \"Image size exceeds\" in str(e):\n",
    "                        raise\n",
    "                    else:\n",
    "                        api_error = True\n",
    "                        raise  # Other errors should not be ignored\n",
    "\n",
    "            # Xu ly output\n",
    "            # Loại bỏ khối ```python ... ```\n",
    "            response = response.text\n",
    "            response = re.sub(r\"^```python\\s*\", \"\", response.strip(), flags = re.IGNORECASE)\n",
    "            response = re.sub(r\"\\s*```$\", \"\", response.strip())\n",
    "            # Thay dấu ngoặc kép cong thành thẳng\n",
    "            response = response.replace(\"“\", '\"').replace(\"”\", '\"')\n",
    "            # Thực thi parsing\n",
    "            response = fix_list_string(response)\n",
    "            meaning_sentences = ast.literal_eval(response)\n",
    "            joined_text = \" \".join(meaning_sentences)\n",
    "            \n",
    "            with open(f\"{implementor}_val_OCR.txt\", \"a+\", encoding = \"utf-8\") as out_file:\n",
    "                out_file.write(f\"Index {count}: \" + joined_text + \"\\n\")\n",
    "        \n",
    "        count += 1\n",
    "        if (count > end_index):\n",
    "            break\n",
    "    \n",
    "    except (Exception, KeyboardInterrupt) as e:  \n",
    "        print(f\"[-] Error: {e if not isinstance(e, KeyboardInterrupt) else 'Interrupted'}\")\n",
    "        \n",
    "        if (count_ocr <= start_index):\n",
    "            break\n",
    "              \n",
    "        with open(f\"{implementor}_val_index.txt\", \"w\", encoding = \"utf-8\") as f:\n",
    "            f.write(f\"{count_ocr} {end_index}\")\n",
    "        \n",
    "        if isinstance(e, KeyboardInterrupt):\n",
    "            break\n",
    "        \n",
    "        if (api_error):\n",
    "            break\n",
    "        \n",
    "        count += 1\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4544fa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to read dataset from the index 22467 to the index 27997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning dataset: 9816it [27:11, 21.37it/s]'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 86aa1d1d-0be7-4fdc-96d0-9e44ce43018b)')' thrown while requesting GET https://huggingface.co/datasets/Namronaldo2004/ViInfographicsVQA/resolve/5823ee92b7596d432a651d64bc8423830b2864f5/data/test_part2-00012-of-00013.parquet\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Scanning dataset: 25324it [11:24:25, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-] Error: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning dataset: 27829it [19:33:03,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Resizing large image at index 27829: original size (2083, 22977)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning dataset: 27997it [20:01:25,  2.57s/it]\n"
     ]
    }
   ],
   "source": [
    "with open (f\"{implementor}_test_index.txt\", 'r', encoding = 'utf-8') as file:\n",
    "    lst = file.read().strip('\\n').split()\n",
    "    start_index = int(lst[0])\n",
    "    end_index = int(lst[1])\n",
    "    print(f\"Start to read dataset from the index {start_index} to the index {end_index}\")\n",
    "    \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "count = 0\n",
    "count_ocr = 0\n",
    "oldImage = None\n",
    "api_error = False\n",
    "\n",
    "for sample in tqdm(test_hf_dataset, desc = \"Scanning dataset\"):\n",
    "    try:\n",
    "        if (count < start_index):\n",
    "            count += 1\n",
    "            count_ocr += 1\n",
    "            continue\n",
    "                                                             \n",
    "        # OCR + Gemini \n",
    "        image = sample[\"image\"]  # Load image from dataset\n",
    "        image_np = np.array(image)\n",
    "        image = Image.fromarray(image_np) \n",
    "        \n",
    "        if count == start_index or imagehash.phash(image) != imagehash.phash(oldImage):\n",
    "            oldImage = image\n",
    "            count_ocr = count\n",
    "            ocr_chunks = reader.readtext(image_np)\n",
    "            ocr_chunks = list(chunk[1] for chunk in ocr_chunks)\n",
    "            \n",
    "            prompt = f\"\"\"Bạn nhận được một danh sách văn bản ngắn, trích xuất từ ảnh infographic (OCR).\n",
    "            \n",
    "            Yêu cầu:\n",
    "            - Gom nhóm các dòng có liên quan theo ngữ cảnh.\n",
    "            - Viết lại thành các câu hoàn chỉnh, ngắn gọn, rõ nghĩa dùng để thực hiện text embedding.\n",
    "            - Trả về **duy nhất một Python list hợp lệ** chứa các câu, ví dụ:\n",
    "            ```python\n",
    "            [\n",
    "                \"Câu hoàn chỉnh 1.\",\n",
    "                \"Câu hoàn chỉnh 2.\",\n",
    "                ...\n",
    "            ]\n",
    "            \n",
    "            Dữ liệu:\n",
    "            {ocr_chunks}\n",
    "            \n",
    "            \"\"\"\n",
    "            \n",
    "            MAX_WEBP_SIZE = 16383\n",
    "            try:\n",
    "                resample_mode = Image.Resampling.LANCZOS\n",
    "            except AttributeError:\n",
    "                resample_mode = Image.LANCZOS  # For Pillow < 10.0\n",
    "\n",
    "            if image.width > MAX_WEBP_SIZE or image.height > MAX_WEBP_SIZE:\n",
    "                print(f\"[!] Resizing large image at index {count}: original size {image.size}\")\n",
    "                \n",
    "                resize_ratio = min(MAX_WEBP_SIZE / image.width, MAX_WEBP_SIZE / image.height)\n",
    "                new_size = (int(image.width * resize_ratio), int(image.height * resize_ratio))\n",
    "                \n",
    "                image = image.resize(new_size, resample=resample_mode)\n",
    "                image_np = np.array(image)  # Update numpy version too\n",
    "\n",
    "            count_429 = 0\n",
    "            while (True):\n",
    "                try:\n",
    "                    response = model.generate_content([prompt, image])\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    if \"429\" in str(e):\n",
    "                        print(\"[-] Received 429 Too Many Requests. Retrying after 10 seconds...\")\n",
    "                        count_429 += 1\n",
    "                        \n",
    "                        if (count_429 < 6):\n",
    "                            sleep(10)\n",
    "                        else:\n",
    "                            api_error = True\n",
    "                            raise\n",
    "                    elif \"Image size exceeds\" in str(e):\n",
    "                        raise\n",
    "                    else:\n",
    "                        api_error = True\n",
    "                        raise  # Other errors should not be ignored\n",
    "\n",
    "            # Xu ly output\n",
    "            # Loại bỏ khối ```python ... ```\n",
    "            response = response.text\n",
    "            response = re.sub(r\"^```python\\s*\", \"\", response.strip(), flags = re.IGNORECASE)\n",
    "            response = re.sub(r\"\\s*```$\", \"\", response.strip())\n",
    "            # Thay dấu ngoặc kép cong thành thẳng\n",
    "            response = response.replace(\"“\", '\"').replace(\"”\", '\"')\n",
    "            # Thực thi parsing\n",
    "            response = fix_list_string(response)\n",
    "            meaning_sentences = ast.literal_eval(response)\n",
    "            joined_text = \" \".join(meaning_sentences)\n",
    "            \n",
    "            with open(f\"{implementor}_test_OCR.txt\", \"a+\", encoding = \"utf-8\") as out_file:\n",
    "                out_file.write(f\"Index {count}: \" + joined_text + \"\\n\")\n",
    "        \n",
    "        count += 1\n",
    "        if (count > end_index):\n",
    "            break\n",
    "    \n",
    "    except (Exception, KeyboardInterrupt) as e:  \n",
    "        print(f\"[-] Error: {e if not isinstance(e, KeyboardInterrupt) else 'Interrupted'}\")\n",
    "        \n",
    "        if (count_ocr <= start_index):\n",
    "            break\n",
    "              \n",
    "        with open(f\"{implementor}_test_index.txt\", \"w\", encoding = \"utf-8\") as f:\n",
    "            f.write(f\"{count_ocr} {end_index}\")\n",
    "        \n",
    "        if isinstance(e, KeyboardInterrupt):\n",
    "            break\n",
    "        \n",
    "        if (api_error):\n",
    "            break\n",
    "        \n",
    "        count += 1\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
